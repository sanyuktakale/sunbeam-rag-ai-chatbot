{
    "course_name": "Mastering Generative AI",
    "url": "https://sunbeaminfo.in/modular-courses/mastering-generative-ai",
    "general_info": {
        "summary": "Course Name : Mastering GenAI | Batch Schedule : 14-Jul-2025   To   03-Sep-2025 | Schedule : Mon - Thu | Duration : 60 Hrs | Timings : 9:00 PM  To  11:00 PM | Fees : Rs. 17900/-"
    },
    "sections": [
        {
            "title": "Course Introduction",
            "content": "Join Amit Kulkarni, an industry expert and certified AI specialist, as he walks you through the Mastering GenAI course at Sunbeam Pune. This program is designed to help you understand, build, and innovate with AI-powered solutions.\n\n                                                \n                                                Click to Register"
        },
        {
            "title": "Syllabus:",
            "content": "Mastering AI Basics\n\n \n\n\n\tOverview of Statistics\n\n\t\n\t\tDefinition and importance of statistics\n\t\tTypes of statistics: descriptive and inferential\n\t\tRole of statistics in data science and machine learning\n\t\tBasic statistical terminology (population, sample, parameter, statistic)\n\t\n\t\n\tSampling\n\t\n\t\tSampling methods\n\t\tsampling distributions\n\t\tCentral Limit Theorem\n\t\n\t\n\tDescriptive Statistics\n\t\n\t\tMeasures of central tendency (mean, median, mode)\n\t\tmeasures of variability (range, variance, standard deviation)\n\t\tskewness and kurtosis\n\t\n\t\n\tProbability:\n\t\n\t\tBasic concepts of probability, conditional probability\n\t\tBayes' theorem.\n\t\tRandom variables and probability distributions\n\t\n\t\n\tDistributions:\n\t\n\t\tNormal distribution\n\t\tBinomial distribution\n\t\tPoisson distribution\n\t\tUniform distribution\n\t\n\t\n\tHypothesis Testing:\n\t\n\t\tNull and alternative hypotheses\n\t\tType I and Type II errors\n\t\tP-values\n\t\tConfidence intervals\n\t\n\t\n\tCorrelation Analysis:\n\t\n\t\tPearson correlation\n\t\tSpearman's rank correlation\n\t\n\t\n\tTime Series Analysis:\n\t\n\t\tTrend analysis\n\t\tSeasonality\n\t\tMoving averages\n\t\tARMA models\n\t\tARIMA models\n\t\n\t\n\tData Visualization:\n\t\n\t\tImportance of data visualization\n\t\tPrinciples of effective data visualization\n\t\tCommon visualization techniques:\n\t\t\n\t\t\t  Histograms\n\t\t\t  Box plots\n\t\t\t  Scatter plots\n\t\t\t  Heatmaps\n\t\t\t  Bar charts\n\t\t\n\t\t\n\t\n\t\n\tData Preprocessing\n\t\n\t\tData cleaning and handling missing values\n\t\tData transformation (normalization, standardization)\n\t\tFeature engineering and selection\n\t\tEncoding categorical variables\n\t\tHandling imbalanced datasets\n\t\tData splitting (training, validation, test sets)\n\t\tData augmentation techniques\n\t\tOutlier detection and handling\n\t\n\t\n\tIntroduction to Machine Learning\n\t\n\t\tOverview of machine learning\n\t\tTypes of machine learning:\n\t\t\n\t\t\tsupervised learning\n\t\t\tunsupervised learning\n\t\t\treinforcement learning\n\t\t\tsemi-supervised learning\n\t\t\n\t\t\n\t\tApplications of machine learning\n\t\tChallenges and limitations of machine learning\n\t\n\t\n\tRegression Analysis\n\t\n\t\tOverview of regression analysis\n\t\tAlgorithms for regression:\n\t\t\n\t\t\t Linear regression\n\t\t\t Ridge regression\n\t\t\t Lasso regression\n\t\t\n\t\t\n\t\tAssumptions of regression analysis\n\t\tModel evaluation metrics (R-squared, adjusted R-squared, RMSE, MAE)\n\t\tModel interpretation and communication of results\n\t\tApplications of regression analysis\n\t\n\t\n\tClassification\n\t\n\t\tOverview of classification\n\t\tTypes of classification\n\t\tEvaluation metrics for classification (Confusion matrix, accuracy, precision, recall, F1-score, ROC-AUC)\n\t\tAlgorithms for classification:\n\t\t\n\t\t\tDecision trees\n\t\t\tk-nearest neighbors (k-NN)\n\t\t\tNaive Bayes\n\t\t\n\t\t\n\t\tEnsemble methods (Bagging, Boosting, Stacking)\n\t\tHyperparameter tuning and model selection\n\t\tCross-validation techniques\n\t\tApplications of classification\n\t\n\t\n\tClustering\n\t\n\t\tOverview of clustering\n\t\tTypes of clustering:\n\t\t\n\t\t\tK-means clustering\n\t\t\tHierarchical clustering\n\t\t\n\t\t\n\t\tEvaluation metrics for clustering (Silhouette score)\n\t\n\t\n\tDimensionality Reduction\n\t\n\t\tOverview of dimensionality reduction\n\t\tImportance of dimensionality reduction\n\t\tTechniques for dimensionality reduction:\n\t\t\n\t\t\t Principal Component Analysis (PCA)\n\t\t\n\t\t\n\t\n\t\n\n\n \n\n \n\nMastering-AI-Advance\n\n\n\tIntroduction to Deep Learning\n\n\t\n\t\tOverview of deep learning\n\t\tDifferences between traditional machine learning and deep learning\n\t\tApplications of deep learning in various domains\n\t\tChallenges and limitations of deep learning\n\t\tOverview of generative AI\n\t\tApplications of generative AI in various domains\n\t\tChallenges and limitations of generative AI\n\t\n\t\n\tDeep Learning Frameworks\n\t\n\t\tOverview of popular deep learning frameworks (TensorFlow, PyTorch, Keras)\n\t\tOverview of generative AI frameworks (Huggingface, Langchain)\n\t\tSetting up the environment\n\t\n\t\n\tArtificial Neural Networks (ANNs)\n\t\n\t\tFeedforward neural networks\n\t\twhat is a perceptron\n\t\tMulti-layer perceptrons (MLPs)\n\t\tActivation functions (ReLU, sigmoid, tanh)\n\t\tLoss functions (mean squared error, cross-entropy)\n\t\tRegression and classification using ANNs\n\t\tModel evaluation metrics (accuracy, precision, recall, F1-score)\n\t\tModel interpretability\n\t\tApplications of ANNs in real-world scenarios\n\t\tHands-on: Build and train ANN model for regression and classification tasks\n\t\n\t\n\tConvolutional Neural Networks (CNNs)\n\t\n\t\tOverview of CNNs and their architecture\n\t\tConvolutional layers and filters\n\t\tPooling layers (max pooling, average pooling)\n\t\tFlattening and fully connected layers\n\t\tApplications of CNNs in image processing and computer vision\n\t\tHands-on: Build and train a CNN for image classification\n\t\n\t\n\tRecurrent Neural Networks (RNNs)\n\t\n\t\tOverview of RNNs and their architecture\n\t\tANN vs CNN vs RNN\n\t\tLong Short-Term Memory (LSTM) networks\n\t\tGated Recurrent Units (GRUs)\n\t\tApplications of RNNs in natural language processing and time series analysis\n\t\tHands-on: Build and train an RNN for text classification or time series prediction\n\t\n\t\n\tGenerative Adversarial Networks (GANs)\n\t\n\t\tOverview of GANs and their architecture\n\t\tGenerator and discriminator networks\n\t\tTraining GANs and challenges\n\t\tApplications of GANs in image generation and data augmentation\n\t\tVariants of GANs (DCGAN, CycleGAN, StyleGAN)\n\t\tHands-on: Build and train a GAN for image generation\n\t\n\t\n\tTransfer Learning\n\t\n\t\tOverview of transfer learning\n\t\tFine-tuning pre-trained models\n\t\tApplications of transfer learning in various domains\n\t\tHands-on: Fine-tune a pre-trained model for a specific task\n\t\n\t\n\tNatural Language Processing (NLP)\n\t\n\t\tOverview of NLP and its applications\n\t\tText preprocessing techniques (tokenization, stemming, lemmatization)\n\t\tWord embeddings (Word2Vec, GloVe, FastText)\n\t\tSequence-to-sequence models\n\t\tAttention mechanisms in NLP\n\t\tNamed Entity Recognition (NER)\n\t\tSentiment analysis\n\t\tFine-tuning pre-trained models for NLP tasks\n\t\tHands-on: Build and train an NLP model for text classification or sentiment analysis\n\t\n\t\n\tLarge Language Models (LLMs)\n\t\n\t\tOverview of LLMs and their architecture\n\t\tTransformer architecture\n\t\tAttention mechanisms\n\t\tPre-training and fine-tuning LLMs\n\t\tApplications of LLMs in natural language processing\n\t\tHands-on: Fine-tune a pre-trained LLM for text generation or classification\n\t\n\t\n\tRetrieval-Augmented Generation (RAG)\n\t\n\t\tOverview of RAG\n\t\tHow RAG works\n\t\tApplications of RAG in natural language processing\n\t\tChallenges and limitations of RAG\n\t\tFuture directions of RAG\n\t\tHands-on: Build a RAG model for a specific task (e.g., chat with PDF, chat with CSV, chat with text)\n\t\tEvaluation metrics for RAG models\n\t\tHands-on: Evaluate the performance of a RAG model\n\t\n\t\n\tAgentic RAG\n\t\n\t\tOverview of agentic RAG\n\t\tHow agentic RAG works\n\t\tApplications of agentic RAG in natural language processing\n\t\tChallenges and limitations of agentic RAG\n\t\tFuture directions of agentic RAG\n\t\tHands-on: Build an agentic RAG model for a specific task\n\t\n\t\n\tFine tuning LLMs\n\t\n\t\tOverview of fine-tuning LLMs\n\t\tHow to fine-tune LLMs\n\t\tApplications of fine-tuning LLMs in natural language processing\n\t\tChallenges and limitations of fine-tuning LLMs\n\t\tFuture directions of fine-tuning LLMs\n\t\tHands-on: Fine-tune an LLM for a specific task\n\t\t \n\t\n\t\n                                                \n                                                Click to Register"
        },
        {
            "title": "Prerequisites:",
            "content": "Beginners with basic python knowledge\n                                                \n                                                Click to Register"
        },
        {
            "title": "Student Feedback:",
            "content": "Amit Kulkarni Sir is truly the best in this field. He explains the basics of technology, which is rare, and makes difficult concepts easy to understand. His syllabus is market-oriented, covering the latest trends.\n\t— Amruta Deole, Senior Software Developer\n\t \n\tThe hands-on projects, prompt engineering techniques, and deployment strategies were especially valuable. A great choice for both freshers and professionals aiming to upskill in Gen AI.\n\t— Rahul Kulkarni, Data Analyst & ML/DL Developer\n\t \n\tAmit Sir answered thousands of questions with a smile. His passion for teaching and deep expertise inspired me. The sessions were technically sound and full of real-world insights.\n\t— Sanket Gawali, Solution Developer\n\t \n\tThe course provided a strong foundation, progressing seamlessly from basics to advanced topics like RAG and LLMs. The balance of theory and practice was perfect.\n\t— Shivani Bhinge, Associate Data Science Engineer\n\t \n\tThis was a zero-to-hero Generative AI course. I can now make an impact in my work using AI. Amit Sir’s humility and support even after the course are unparalleled.\n\t— Chaitanya Takalikar, Software Engineer\n                                                \n                                                Click to Register"
        }
    ],
    "batch_schedule_table": [
        {
            "Sr.No": "1",
            "Batch Code": "AI-O-002(Combo A+B)",
            "Start Date": "14-Jul-2025",
            "End Date": "03-Sep-2025",
            "Time": "9:00 PM  To  11:00 PM"
        },
        {
            "Sr.No": "2",
            "Batch Code": "Mastering-AI-Basics-O-01(A)",
            "Start Date": "14-Jul-2025",
            "End Date": "06-Aug-2025",
            "Time": "9:00 PM  To  11:00 PM"
        },
        {
            "Sr.No": "3",
            "Batch Code": "Mastering-AI-ADV-O-01(B)",
            "Start Date": "07-Aug-2025",
            "End Date": "03-Sep-2025",
            "Time": "9:00 PM  To  11:00 PM"
        }
    ]
}